package algorithms_datastructures;

/* АНАЛИЗ АЛГОРИТМА
 * - space complexity: сколько места занимает структура данных
 *      - учитывая текущую доступность размеров памяти, это не так важно
 *
 * - time complexity: сколько времени уходит на выполнение алгоритма
 *      - зависит от порядка роста при росте количества элементов:
 *          - линейный рост:
 *              - 100 шт. - 10 мс
 *              - 1000 шт. - 100 мс
 *              - 10000 шт. - 1000 мс
 *          - квадратичный рост:
 *              - 100 шт. - 10 мс
 *              - 1000 шт. - 1000 мс
 *              - 10000 шт. - 100000 мс
 *
 *      - предполагается, что:
 *          - происходит worst case scenario
 *              - напр. при Bubble Sort предполагается, что массив изначально сортирован в обратную
 *              сторону, а при поиске элемент отстутсвует
 *              - если worst case scenario отличается от усредненного, то указываются оба
 *          - мы не ограничены в памяти
 *          - мы считываем с RAM
 *          - каждая операция (+, -, *, /, =, <, >) занимает 1 единицу времени
 *          - каждая операция доступа к памяти занимает 1 единицу времени
 *          - точность времени не важна, т.к. она плавает в разных условиях */


/* ПОРЯДОК РОСТА
 * - описывает, как растет сложность А с увеличением размера входных данных
 *
 * - О-нотация ("Ordnung" - порядок): O(f(x)), где f(x) — формула, выражающая сложность алгоритма
 *      - в формуле может присутствовать переменная n, представляющая размер входных данных
 *
 * - от лучшего к худшему: const <= log n <= root n <= n <= n * log(n) <= n^2 <= n^3 <= 2^n <= n!
 *
 * - виды:
 *      - константный: О(1): t(n) = 17
 *          - отличный
 *          - сложность не зависит от размера входных данных
 *          - напр. доступ к хеш таблице
 *
 *      - логарифмический: O( log(n)): t(n) = 3 * log n
 *          - хороший
 *          - растет на константу - при увеличении n, сложность увеличивается на константу
 *          меньше количества n
 *          - по дефолту логарифм по основанию 2
 *          - напр. Binary Search Tree сортированной таблицы
 *
 *      - подлинейный: O(<n)
 *          - хороший
 *          - лучше линейного, но хуже логарифмического
 *          - напр., поиск при помощи параллельного выполнения
 *
 *      - линейный: O(n): t(n) = 20n - 4
 *          - неплохой
 *          - растет пропорционально с n - если n удваивается, сложность тоже удваивается
 *          - напр., посчитать сумму элементов массива
 *
 *      - линеарифметический: O(n * log(n)): t(n) = 12n * log n + 100n
 *          - плохой
 *          - растет кратно константе
 *          - напр. Quick Sort, Merge Sort
 *
 *      - квадратичный: O(n^2): t(n) = 3n^2 + 5n - 2
 *          - ужасный
 *          - растет квадратично при увеличении данных
 *              - т.е. луп в лупе
 *          - напр. Bubble Sort
 *
 *      - кубический: O(n^3): t(n) = 8n^3 + 3n^2
 *          - ужасный
 *          - сложность растет кубически при увеличении данных
 *              - т.е. луп в лупе в лупе
 *
 *      - экспоненциальный: O(c^n): t(n) = 2^n + 18n^2 + 3n
 *          - ужасный
 *          - растет на основе экспоненты n константы c
 *          - напр. Travelling Salesman при помощи динамического программирования
 *
 *      - факториальный - O(n!)
 *          - ужасный
 *          - растет пропорционально произведению всех чисел
 *          - напр. Travelling Salesman при помощи brute force */


public class OrderOfComplexity {

    /* Константный O(1) */
    public int GetCount(int[] items) {
        return items.length;
    }


    /*линейный O(n)*/
    public long GetSum(int[] items) {
        long sum = 0;

        for (int item : items) {
            sum += item;
        }

        return sum;
    }

    /*логарифмический: O( log n)*/


}
